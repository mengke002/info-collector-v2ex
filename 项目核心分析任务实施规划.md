# 核心分析任务实施规划

本文档整合了针对`rss-info-collector`项目中两大核心功能——“科技与创投新闻分析”与“深度内容与社区讨论分析”——的全面实施规划。**此版本特别优化了第二部分“深度内容与社区讨论分析”的方案，使其更强大、更具可操作性。**

---

## **项目背景与结构上下文**

本规划旨在为现有 `rss-info-collector` 项目添加两大核心分析功能。为确保实施的顺畅，特补充以下项目结构与工作流的上下文信息，以便将新功能无缝集成到现有框架中。

### **1. 项目当前工作流与入口**

*   **手动执行**: 项目的主要入口是 `main.py`。通过命令行（未来可能通过参数）可以手动触发在 `src/tasks.py` 中定义的各项任务，例如 `python main.py`。
*   **自动化执行**: 项目已配置了通过 GitHub Actions (`.github/workflows/data_collect_task.yml`) 进行的自动化工作流，主要负责定时执行基础的数据采集任务 (`run_fetch_and_save_task`)。新的分析与报告生成任务在开发完成后，也可以被集成到类似（或全新）的自动化工作流中，实现无人值守的洞察报告生成。

### **2. 核心模块现有及规划职责**

*   `src/config.py`: 负责加载 `config.ini` 配置文件，为整个应用提供数据库路径、API密钥以及LLM模型名称（如 `fast_model`, `smart_model`）等静态配置。
*   `src/database.py`: 封装了所有数据库交互（基于 `MySQL`，使用 `PyMySQL` 驱动），提供文章的增、删、改、查等原子操作接口。
*   `src/rss_parser.py` & `src/content_enhancer.py`: 分别负责解析RSS源的初始数据和进一步抓取文章全文内容。
*   `src/tasks.py`: 作为项目的任务调度层，编排原子操作形成高级任务。例如，现有的 `run_fetch_and_save_task` 整合了RSS解析、内容增强和数据库存储。本规划中提到的 `run_tech_news_analysis_task` 和 `run_community_analysis_task` 将作为新的函数在此文件中定义。
*   `src/analyzer.py` **(主要新增模块)**: 此模块当前可能为空或不存在。本规划将赋予其核心职责：执行所有与LLM相关的分析、数据提炼和洞察生成。它将是实现“从信息到智慧”转变的关键。
*   `src/report_generator.py` **(主要新增模块)**: 此模块当前同样可能为空或不存在。其职责是获取 `analyzer.py` 的分析结果，并依据本规划定义的结构（如“洋葱模型”），动态生成内容丰富、阅读体验优秀的 Markdown 格式报告。

### **3. 数据模型与关键字段**

*   本次项目内容数据存储在MySQL数据库的 `articles` 表中。在 `src/database.py` 中定义了其表结构，关键字段包括：
    *   `id`: 主键
    *   `guid`: 文章唯一标识符
    *   `title`: 标题
    *   `link`: 原始链接
    *   `source_feed`: 信息来源 (如 `techcrunch`, `ycombinator`)
    *   `published_date`: 发布日期
    *   `content`: RSS源提供的原始内容或摘要
    *   `full_content`: 经过 `content_enhancer` 抓取的完整文章内容，是本次分析任务的主要信息输入。

### **4. 项目依赖与环境**

*   项目的所有Python依赖均在 `requirements.txt` 文件中进行管理。

---

## **第一部分：科技与创投新闻分析与报告**

*(此部分沿用之前的规划文档内容，保持不变)*

### **1.1 总体目标与核心理念**

我们的核心目标不仅仅是聚合新闻，而是要创造价值。报告的深度不取决于信息的多少，而在于**连接信息、揭示关系、预测趋势**的能力。

**核心理念：从“事件复述”到“影响解读”**

每一份报告都应致力于回答两个核心问题：
1.  **“So What?”** (所以这又怎样？) - 这条新闻的真正意义和影响是什么？
2.  **“What's Next?”** (接下来会发生什么？) - 基于此事件，未来的趋势和机会在哪里？

---
---

## **第二部分：深度内容与社区讨论分析与报告**

此部分针对 `indiehackers` 和 `ezindie` 等内容源，目标是从长篇文章和社区讨论中挖掘可行的见解、经验和趋势。**方案的核心是采用更合理、更强大的两步分析法，简化操作，增强单篇分析深度，并在此基础上进行更高维度的综合洞察。**

### **2.1 重构后的分析流程：两步走战略**

1.  **第一步：单篇深度解析 (Per-Article Deep Analysis)**
    *   **执行者**: `fast_model`
    *   **目标**: 对**每一篇**来自 `indiehackers`、`ezindie` 的文章进行一次全面而深入的结构化解析。
    *   **产出**: 为每篇文章生成一个包含多维度信息的JSON对象，并存入数据库。

2.  **第二步：跨文章综合洞察 (Cross-Article Synthesis)**
    *   **执行者**: `smart_model`
    *   **目标**: 聚合第一步产出的所有结构化信息，进行趋势识别、模式发现和观点碰撞，生成宏观报告。
    *   **产出**: 一份综合性的分析报告（Markdown格式），并存入数据库。

### **2.2 第一步：单篇深度解析 (Prompt与实施)**

#### **2.2.1 数据库准备**

在  `indiehackers` 和 `ezindie` 对应的文章表中添加两个新字段。

*   **SQL指令示例**:
    ```sql
    ALTER TABLE xxx
    ADD COLUMN deep_analysis_data TEXT,
    ADD COLUMN deep_analysis_status SMALLINT DEFAULT 0 COMMENT '0=待处理, 1=处理成功, -1=处理失败';
    ```

#### **2.2.2 强大的信息抽取Prompt**

此Prompt是新流程的核心，强制`fast_model`进行多维度思考并结构化输出。

```prompt
你是一位顶尖的独立开发者社区分析师和创业导师。你的任务是深入分析给定的文章，并以结构化的JSON格式，提炼出其中所有有价值的信息。

请严格按照“事实层”、“观察层”、“思考层”三个维度进行分析，并遵循最终的JSON输出格式。

**分析维度指南:**

1.  **事实层 (Factual Layer)**: 客观地提取文章明确提到的信息。
    *   `article_type`: 判断文章类型，从 ['经验分享', '案例研究', '技术教程', '观点讨论', '产品发布', '问答'] 中选择一个最贴切的。
    *   `summary`: 用2-3句话总结文章的核心内容。
    *   `key_entities`: 提取文章中提到的关键实体，如产品名、公司名、技术栈、关键人物等。

2.  **观察层 (Observational Layer)**: 提炼作者的核心观点和可直接复用的信息。
    *   `core_insights`: 总结作者的核心洞察或主要论点，以列表形式呈现。
    *   `actionable_playbook`: 提炼出具体的、可操作的步骤或策略。如果没有，则返回空数组。
    *   `quantitative_results`: 提取所有能量化的结果，如“月收入达到$10,000”、“用户增长50%”、“转化率从1%提升到5%”等。

3.  **思考层 (Deeper Analysis Layer)**: 进行批判性思考和延伸分析。
    *   `underlying_reason`: 分析作者成功的潜在原因或其观点背后的深层逻辑是什么？
    *   `limitations_and_caveats`: 这些经验或观点有什么局限性、适用前提或潜在风险？
    *   `sparks_of_inspiration`: 这篇文章最能激发思考或带来启发的一点是什么？

**输入文章:**
'''
{article_content}
'''

**你的输出必须是一个单一、有效的JSON对象**，并严格遵循以下结构。所有内容值都必须是**中文**：
'''json
{
  "factual_layer": {
    "article_type": "经验分享",
    "summary": "文章的核心内容摘要。",
    "key_entities": ["产品名", "技术栈", "人物A"]
  },
  "observational_layer": {
    "core_insights": [
      "核心洞察或论点一。",
      "核心洞点或论点二。"
    ],
    "actionable_playbook": [
      "第一步：做什么。",
      "第二步：做什么。"
    ],
    "quantitative_results": [
      "月收入达到 $XXXX",
      "用户数从 Y 增长到 Z"
    ]
  },
  "deeper_analysis_layer": {
    "underlying_reason": "作者成功的关键可能在于其独特的市场切入点，而非仅仅是营销技巧。",
    "limitations_and_caveats": "此方法高度依赖于作者的个人品牌，对于没有粉丝基础的初学者可能不适用。",
    "sparks_of_inspiration": "将一个看似饱和的市场进行垂直细分，仍然能找到蓝海机会。"
  }
}
'''
```

### **2.3 第二步：跨文章综合洞察 (Prompt与实施)**

#### **2.3.1 数据库准备**

建议创建一个新表 `synthesis_reports` 来存储报告。

*   **SQL指令示例**:
    ```sql
    CREATE TABLE synthesis_reports (
        id INT AUTO_INCREMENT PRIMARY KEY,
        report_type VARCHAR(255),
        start_date DATE,
        end_date DATE,
        content TEXT,
        source_article_ids JSON,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    ```

#### **2.3.2 综合洞察Prompt**

此Prompt驱动`smart_model`进行宏观分析。

```prompt
你是一位卓越的行业分析师和编辑，擅长从大量结构化信息中发现趋势、总结模式并生成富有洞察的报告。

我现在提供给你过去一周从独立开发者社区收集的多篇文章的深度分析数据（一个JSON数组）。

**你的任务是:**

1.  **识别本周热点**: 统计`article_type`和`key_entities`，找出讨论最频繁的主题和产品/技术。
2.  **总结共性模式**: 在所有`actionable_playbook`和`underlying_reason`中，发现被反复提及的成功模式或策略。
3.  **发现矛盾与新奇观点**: 找出`core_insights`中相互矛盾或特别新颖的观点。
4.  **生成一份综合洞察周报**: 以清晰、易读的Markdown格式输出你的报告。

**输入数据 (JSON数组):**
'''json
[
  {
    "article_id": 101,
    "factual_layer": { "article_type": "经验分享", ... },
    "observational_layer": { "core_insights": ["内容营销是关键"], ... },
    ...
  },
  {
    "article_id": 102,
    "factual_layer": { "article_type": "案例研究", "key_entities": ["AI Wrapper"] ... },
    "observational_layer": { "core_insights": ["找到一个好的利基市场至关重要"], ... },
    ...
  }
]
'''

**请按照以下Markdown结构生成你的周报:**

# 独立开发者社区洞察周报 ([YYYY-MM-DD] - [YYYY-MM-DD])

## 🚀 本周热点速览

*   **热门主题**: [例如：本周讨论最多的主题是“早期用户获取”和“AI工具应用”。]
*   **焦点产品/技术**: [例如：社区对“AI Wrapper”、“Notion API”的讨论热度很高。]

## 🛠️ 本周策略风向标：发现共同的成功秘诀

*   **模式一**: [例如：多个“经验分享”类文章都强调了“先在垂直社区建立声誉，再推广产品”的策略。]
*   **模式二**: [例如：从多个案例的`underlying_reason`来看，“解决自己遇到的真实问题”是产品成功的首要前提。]

## 💡 观点碰撞：值得深思的讨论

*   **矛盾点**: [例如：关于“是否需要融资”，文章[105]认为独立开发者应保持精简，而文章[108]的案例则展示了小额融资加速发展的可能性。]
*   **新奇视角**: [例如：文章[110]提出了一个有趣的观点，认为“产品的‘无聊’程度与商业成功率成正比”，这与社区普遍追求创新的风潮形成对比。]

## 📚 本周精选案例/经验速读

*   **案例 [文章ID]**: [这里可以引用某篇案例研究的`summary`和`quantitative_results`]
*   **经验 [文章ID]**: [这里可以引用某篇经验分享的`summary`和`actionable_playbook`中最核心的一条]

---
*报告基于对 [N] 篇文章的分析生成。*
```

### **2.4 架构与落地实施建议**

为将此方案落地，建议在现有项目结构上进行如下扩展：

1.  **数据库 (`database.py`)**: 
    *   执行上述`ALTER TABLE`和`CREATE TABLE`语句以更新数据库结构。
    *   在`database.py`中添加对应的CRUD函数，用于操作`articles`表的新字段和`synthesis_reports`新表。
2.  **分析器 (`src/analyzer.py`)**: 
    *   创建`analyze_single_article_deeply()`函数，负责调用`fast_model`并处理第一步的Prompt。需包含JSON校验和错误处理逻辑（用正则模糊匹配托底）。
    *   创建`synthesize_weekly_insights()`函数，负责调用`smart_model`并处理第二步的Prompt，生成最终报告的Markdown内容。
3.  **任务层 (`src/tasks.py`)**: 
    *   创建新的主任务函数`run_community_analysis_and_report_task()`。
    *   此函数将作为总指挥，编排整个流程：
        1.  调用`database.py`查询所有待分析的文章。
        2.  遍历文章，逐一调用`analyzer.py`中的函数进行单篇深度解析，并更新数据库。
        3.  调用`database.py`获取一个周期内（如一周）所有已分析的数据。
        4.  调用`analyzer.py`中的函数完成跨文章综合洞察。
        5.  将最终报告内容存入`synthesis_reports`表。
5.  **入口 (`main.py`)**: 
    *   在`main.py`中添加对新任务的调用入口，例如通过命令行参数 `python main.py community_report` 来触发`run_community_analysis_and_report_task`。