"""
V2EXæ™ºèƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
åŸºäºèŠ‚ç‚¹çš„çƒ­ç‚¹å†…å®¹åˆ†æå’ŒMarkdownæŠ¥å‘Šç”Ÿæˆ
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone, timedelta

from .database import db_manager
from .llm_client import llm_client
from .config import config


class V2EXReportGenerator:
    """V2EXæ™ºèƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.db = db_manager
        self.llm = llm_client

        # æŠ¥å‘Šé…ç½®
        report_config = config.get_report_config()
        self.top_topics_per_node = report_config.get('top_topics_per_node', 50)
        self.top_replies_per_topic = 10
        self.max_content_length = 50000
    
    def get_beijing_time(self) -> datetime:
        """è·å–å½“å‰åŒ—äº¬æ—¶é—´"""
        return datetime.now(timezone.utc) + timedelta(hours=8)
    
    def _truncate_content_for_logging(self, content: str, max_length: int = 300) -> str:
        """
        ä¸ºæ—¥å¿—è®°å½•æˆªå–å†…å®¹ï¼Œé¿å…æš´éœ²è¿‡å¤šæ•æ„Ÿä¿¡æ¯
        
        Args:
            content: è¦æˆªå–çš„å†…å®¹
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            æˆªå–åçš„å†…å®¹
        """
        if len(content) <= max_length:
            return content
        
        truncated = content[:max_length]
        # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„è¡Œæˆ–å¥å­
        last_newline = truncated.rfind('\n')
        if last_newline > max_length // 2:  # å¦‚æœæ‰¾åˆ°äº†åˆç†ä½ç½®çš„æ¢è¡Œç¬¦
            truncated = truncated[:last_newline]
        
        return f"{truncated}... [å†…å®¹è¢«æˆªæ–­ï¼Œæ€»é•¿åº¦: {len(content)} å­—ç¬¦]"
    
    def _get_hotspot_prompt_template(self) -> str:
        """è·å–çƒ­ç‚¹åˆ†æçš„â€œè¶…çº§æç¤ºè¯â€æ¨¡æ¿ï¼ˆæƒ…å¢ƒæ„ŸçŸ¥å¼ºåŒ–ç‰ˆï¼‰"""
        return """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å¤šé¢†åŸŸåˆ†æå¸ˆï¼Œæ“…é•¿ä»ä¸åŒç¤¾ç¾¤çš„è®¨è®ºä¸­æŒ–æ˜å‡ºé’ˆå¯¹ç‰¹å®šäººç¾¤çš„æ·±åˆ»æ´å¯Ÿã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä»¥ä¸‹æ¥è‡ªV2EXç¤¾åŒºç‰¹å®šèŠ‚ç‚¹ï¼ˆæ¿å—ï¼‰çš„åŸå§‹è®¨è®ºææ–™ï¼Œå¹¶æ’°å†™ä¸€ä»½ç»“æ„æ¸…æ™°ã€ç”±æµ…å…¥æ·±çš„æ´å¯ŸæŠ¥å‘Šã€‚

**åˆ†æåŸåˆ™:**
1.  **æƒ…å¢ƒæ„ŸçŸ¥ (Context-Aware)**: é¦–å…ˆï¼Œæ³¨æ„è¿™äº›ä¸»é¢˜ä¸»è¦æ¥è‡ªå“ªäº›èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ 'é…·å·¥ä½œ', 'èŒåœºè¯é¢˜', 'åˆ†äº«å‘ç°'ï¼‰ã€‚èŠ‚ç‚¹çš„å±æ€§å†³å®šäº†åˆ†æçš„è§†è§’å’Œä»·å€¼å–å‘ã€‚
2.  **å¿ äºåŸæ–‡**: æ‰€æœ‰çš„åˆ†æå’Œæ´å¯Ÿéƒ½å¿…é¡»åŸºäºä¸‹æ–‡æä¾›çš„åŸå§‹ææ–™ã€‚
3.  **å¯è¿½æº¯æ€§**: ä½ çš„æ¯ä¸€æ¡ç»“è®ºã€æ´å¯Ÿå’Œå»ºè®®ï¼Œéƒ½å¿…é¡»åœ¨å¥æœ«ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚è¿™æ˜¯ç¡¬æ€§è¦æ±‚ã€‚
4.  **ç”±æµ…å…¥æ·±**: æŠ¥å‘Šç»“æ„å¿…é¡»ä»è¡¨å±‚ä¿¡æ¯æ€»ç»“ï¼Œé€æ­¥è¿‡æ¸¡åˆ°æ·±å±‚è¶‹åŠ¿å’Œæˆ˜ç•¥å»ºè®®ã€‚

---
**åŸå§‹è®¨è®ºææ–™ (å·²ç¼–å·ï¼ŒåŒ…å«èŠ‚ç‚¹ä¿¡æ¯):**
{content}
---

**ä½ çš„æŠ¥å‘Šç”Ÿæˆä»»åŠ¡:**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹å››ä¸ªå±‚æ¬¡çš„åˆ†ææ¡†æ¶ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„MarkdownæŠ¥å‘Šã€‚

**ç¬¬ä¸€å±‚æ¬¡ï¼šçƒ­é—¨ä¸»é¢˜æ¦‚è§ˆ (Top Topics Overview)**
*   ä»»åŠ¡ï¼šé€šè¯»æ‰€æœ‰ææ–™ï¼Œä¸ºæ¯ä¸ªçƒ­é—¨ä¸»é¢˜æ’°å†™ä¸€ä¸ªç®€æ˜æ‰¼è¦çš„æ‘˜è¦ã€‚
*   è¦æ±‚ï¼šæ¸…æ™°æ€»ç»“æ¯ä¸ªä¸»é¢˜çš„æ ¸å¿ƒè®®é¢˜ã€ä¸»è¦è®¨è®ºæ–¹å‘å’Œæœ€ç»ˆçš„æ™®éå…±è¯†æˆ–ç»“è®ºã€‚

**ç¬¬äºŒå±‚æ¬¡ï¼šæ ¸å¿ƒæ´å¯Ÿæç‚¼ (Key Insights Extraction)**
*   ä»»åŠ¡ï¼šåŸºäºç¬¬ä¸€å±‚æ¬¡çš„æ€»ç»“ï¼Œå¹¶ç»“åˆä½ å¯¹èŠ‚ç‚¹å±æ€§çš„ç†è§£ï¼Œä»å…¨å±€è§†è§’æç‚¼å‡ºæœ€å…³é”®çš„ã€è¶…è¶Šå•ä¸ªä¸»é¢˜çš„æ´å¯Ÿã€‚
*   è¦æ±‚ï¼šæ´å¯Ÿåº”åæ˜ è¯¥èŠ‚ç‚¹ç”¨æˆ·çš„æ ¸å¿ƒå…³åˆ‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ˜¯'é…·å·¥ä½œ'èŠ‚ç‚¹ï¼Œæ´å¯Ÿå¯èƒ½å…³äºæ‹›è˜è¶‹åŠ¿ï¼›å¦‚æœæ˜¯'èŒåœºè¯é¢˜'ï¼Œå¯èƒ½å…³äºè¡Œä¸šç„¦è™‘ã€‚è‡³å°‘æç‚¼5ä¸ªç‹¬ç«‹çš„ã€æœ‰ä»·å€¼çš„æ´å¯Ÿç‚¹ã€‚

**ç¬¬ä¸‰å±‚æ¬¡ï¼šè¶‹åŠ¿ä¸ä¿¡å·åˆ†æ (Trends & Signals Analysis)**
*   ä»»åŠ¡ï¼šåœ¨æ‰€æœ‰è®¨è®ºä¸­å¯»æ‰¾é‡å¤å‡ºç°çš„æ¨¡å¼ã€æ–°å…´çš„æ¦‚å¿µå’Œæ™®éå­˜åœ¨çš„é—®é¢˜ã€‚åˆ†æçš„ä¾§é‡ç‚¹åº”ä¸èŠ‚ç‚¹å±æ€§ä¿æŒä¸€è‡´ã€‚
*   è¦æ±‚ï¼š
    *   **çƒ­è®®è¶‹åŠ¿/æ–°é£å‘**: è¯†åˆ«å¹¶åˆ—å‡ºè¢«çƒ­è®®çš„æ–°é²œäº‹ç‰©ã€è§‚ç‚¹æˆ–è¶‹åŠ¿ã€‚ä¾‹å¦‚ï¼ŒæŠ€æœ¯èŠ‚ç‚¹ä¸­çš„â€œæ–°å·¥å…·â€ï¼Œç”Ÿæ´»èŠ‚ç‚¹ä¸­çš„â€œæ–°æ¶ˆè´¹æ–¹å¼â€ï¼ŒèŒåœºèŠ‚ç‚¹ä¸­çš„â€œæ–°æ±‚èŒç­–ç•¥â€ã€‚
    *   **æ™®éç—›ç‚¹/å…±åŒéœ€æ±‚**: æ€»ç»“è¯¥ç¤¾ç¾¤å…±åŒé¢ä¸´çš„æŒ‘æˆ˜æˆ–æœªè¢«æ»¡è¶³çš„éœ€æ±‚ã€‚
    *   **è®¨è®ºçš„å†…åœ¨å…³è”**: åˆ†æä¸åŒçƒ­ç‚¹è¯é¢˜ä¹‹é—´æ˜¯å¦å­˜åœ¨å› æœã€å‘¼åº”æˆ–çŸ›ç›¾çš„å…³ç³»ã€‚

**ç¬¬å››å±‚æ¬¡ï¼š actionable å»ºè®® (Actionable Recommendations)**
*   ä»»åŠ¡ï¼šåŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œä¸ºè¯¥èŠ‚ç‚¹çš„æ ¸å¿ƒç”¨æˆ·ç¾¤ä½“æä¾›å…·ä½“ã€å¯è¡Œçš„å»ºè®®ã€‚
*   è¦æ±‚ï¼šå»ºè®®å¿…é¡»æœ‰é«˜åº¦çš„é’ˆå¯¹æ€§ã€‚ä¾‹å¦‚ï¼Œä¸è¦æ€»æ˜¯ç»™â€œå¼€å‘è€…â€æå»ºè®®ï¼Œå¦‚æœèŠ‚ç‚¹æ˜¯'Apple'ï¼Œå°±ç»™Appleç”¨æˆ·æå»ºè®®ï¼›å¦‚æœèŠ‚ç‚¹æ˜¯'åˆ›ä¸š'ï¼Œå°±ç»™åˆ›ä¸šè€…æå»ºè®®ã€‚

---

**è¯·ä¸¥æ ¼éµç…§ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºä½ çš„å®Œæ•´æŠ¥å‘Š:**

# ğŸ“ˆ V2EXç¤¾åŒºçƒ­ç‚¹ä¸æƒ…æŠ¥æ´å¯ŸæŠ¥å‘Š

## ä¸€ã€çƒ­é—¨ä¸»é¢˜æ¦‚è§ˆ (Top Topics Overview)

### 1. [ä¸»é¢˜Açš„æ ‡é¢˜]
*   **æ ¸å¿ƒå†…å®¹**: [å¯¹è¯¥ä¸»é¢˜çš„æ ¸å¿ƒè®®é¢˜ã€è®¨è®ºç„¦ç‚¹å’Œä¸»è¦ç»“è®ºè¿›è¡Œæ‘˜è¦ã€‚] [Source: T_n]

### 2. [ä¸»é¢˜Bçš„æ ‡é¢˜]
*   **æ ¸å¿ƒå†…å®¹**: [åŒä¸Šã€‚] [Source: T_m]

...(ç½—åˆ—æœ€é‡è¦çš„5-10ä¸ªä¸»é¢˜)

---

## äºŒã€æ ¸å¿ƒæ´å¯Ÿ (Executive Summary)

*   **æ´å¯Ÿä¸€**: [ç”¨ä¸€å¥è¯é«˜åº¦æ¦‚æ‹¬ä½ å‘ç°çš„æœ€é‡è¦çš„è¶‹åŠ¿æˆ–æ´å¯Ÿã€‚ä¾‹å¦‚ï¼š'é…·å·¥ä½œ'èŠ‚ç‚¹çš„æ‹›è˜éœ€æ±‚æ˜¾ç¤ºï¼Œè¿œç¨‹å·¥ä½œå²—ä½åœ¨å‡å°‘ï¼Œå¯¹å¤åˆå‹äººæ‰çš„éœ€æ±‚åœ¨å¢åŠ ã€‚] [Sources: T1, T5]
*   **æ´å¯ŸäºŒ**: [ä¾‹å¦‚ï¼š'åˆ†äº«å‘ç°'èŠ‚ç‚¹ä¸­ï¼Œå…³äºâ€œå¹³æ›¿â€æ¶ˆè´¹çš„è®¨è®ºæ¿€å¢ï¼Œåæ˜ å‡ºç”¨æˆ·åœ¨æ¶ˆè´¹å†³ç­–ä¸Šæ›´è¶‹äºç†æ€§ã€‚] [Sources: T2, T9]
*   **æ´å¯Ÿä¸‰**: [ç¬¬ä¸‰ä¸ªé‡è¦æ´å¯Ÿã€‚] [Source: T4]
*   ...(è‡³å°‘5æ¡)

---

## ä¸‰ã€è¶‹åŠ¿ä¸ä¿¡å·æ·±åº¦åˆ†æ (In-depth Analysis of Trends & Signals)

### ğŸš€ çƒ­è®®è¶‹åŠ¿ä¸æ–°é£å‘
*   **[è¶‹åŠ¿/é£å‘A]**: [å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å¾ˆçƒ­é—¨ï¼Œä»¥åŠåœ¨è®¨è®ºä¸­æ˜¯å¦‚ä½•ä½“ç°çš„ï¼Ÿ] [Source: T3]
*   **[è¶‹åŠ¿/é£å‘B]**: [åŒä¸Šã€‚] [Source: T7]
*   ...(è‡³å°‘3æ¡)

### âš ï¸ æ™®éç—›ç‚¹ä¸å…±åŒéœ€æ±‚
*   **[ç—›ç‚¹/éœ€æ±‚A]**: [æè¿°è¯¥èŠ‚ç‚¹ç”¨æˆ·æ™®éé‡åˆ°çš„ä¸€ä¸ªé—®é¢˜æˆ–æŒ‘æˆ˜ï¼Œå¹¶åˆ†æå…¶èƒŒåçš„åŸå› ã€‚] [Source: T5]
*   **[ç—›ç‚¹/éœ€æ±‚B]**: [åŒä¸Šã€‚] [Source: T10]
*   ...(è‡³å°‘3æ¡)

### ğŸ”— çƒ­ç‚¹é—´çš„å†…åœ¨å…³è”
*   **[å…³è”æ€§åˆ†æ]**: [è¯¦ç»†é˜è¿°ä½ å‘ç°çš„ä¸åŒçƒ­ç‚¹ä¹‹é—´çš„è”ç³»ã€‚ä¾‹å¦‚ï¼š'èŒåœºè¯é¢˜'ä¸­å¯¹â€œ35å²å±æœºâ€çš„ç„¦è™‘ï¼ˆä¸»é¢˜Aï¼‰ä¸'é…·å·¥ä½œ'ä¸­â€œæ‹›è˜è¦æ±‚å¹´é¾„ä¸Šé™â€çš„è®¨è®ºï¼ˆä¸»é¢˜Bï¼‰å½¢æˆäº†ç›¸äº’å°è¯ã€‚] [Sources: T1, T6]

---

## å››ã€ actionable å»ºè®® (Actionable Recommendations)

### [é’ˆå¯¹è¯¥èŠ‚ç‚¹æ ¸å¿ƒç”¨æˆ·çš„å»ºè®®ï¼Œä¾‹å¦‚ï¼šç»™æ±‚èŒè€…çš„å»ºè®® / ç»™Appleäº§å“ç”¨æˆ·çš„å»ºè®® / ç»™åˆ›ä¸šè€…çš„å»ºè®®]
*   [åŸºäºä»¥ä¸Šåˆ†æï¼Œæå‡º2-3æ¡å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ±‚èŒè€…ï¼šâ€œé‰´äºå¸‚åœºå¯¹å¤åˆå‹äººæ‰çš„éœ€æ±‚å¢åŠ ï¼Œå»ºè®®åœ¨æ·±åŒ–ä¸“ä¸šæŠ€èƒ½çš„åŒæ—¶ï¼Œè¡¥å……é¡¹ç›®ç®¡ç†æˆ–äº§å“è®¾è®¡çŸ¥è¯†ã€‚â€ [Source: T1]]
*   [ç¬¬äºŒæ¡å»ºè®®ã€‚ä¾‹å¦‚ï¼Œå¯¹äºåˆ›ä¸šè€…ï¼šâ€œç¤¾åŒºå¯¹â€˜å‡ºæµ·â€™è¯é¢˜çš„åé¦ˆæ™®éç§¯æï¼Œä½†æ™®éæåˆ°æœ¬åœ°åŒ–æ”¯ä»˜æ˜¯å…³é”®éš¾ç‚¹ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³æ”¯ä»˜æ¸ é“é—®é¢˜ã€‚â€ [Source: T8]]
"""    

    def _format_topics_for_analysis(self, hot_topics_data: List[Dict[str, Any]]) -> str:
        """å°†æ‰€æœ‰çƒ­é—¨ä¸»é¢˜åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æ¡£ç”¨äºLLMç»Ÿä¸€åˆ†æ"""
        content_parts = [
            f"""=== V2EXçƒ­é—¨ä¸»é¢˜ç»¼åˆåˆ†ææ–‡æ¡£ ===""",
            f"æ€»è®¡ {len(hot_topics_data)} ä¸ªçƒ­é—¨ä¸»é¢˜",
            "",
        ]
        
        for i, topic_data in enumerate(hot_topics_data, 1):
            topic = topic_data['topic']
            replies = topic_data['replies']
            
            content_parts.extend([
                f"\n### [Source: T{i}] {topic['title']}",
                f"- èŠ‚ç‚¹: {topic['node_name']}",
                f"- ä½œè€…: {topic['member_username']}",
                f"- å›å¤æ•°: {topic['replies']}",
                f"- æ„Ÿè°¢æ•°: {topic['total_thanks_count']}",
                f"- çƒ­åº¦: {topic['hotness_score']:.2f}",
                f"- URL: {topic['url']}",
                ""
            ])
            
            if topic.get('content'):
                content = topic['content'].strip()
                if len(content) > 800: content = content[:800] + "..."
                content_parts.extend(["**ä¸»è´´å†…å®¹:**", content, ""])
            
            if replies:
                content_parts.append("**çƒ­é—¨å›å¤:**")
                for j, reply in enumerate(replies[:5], 1): # Limit to 5 replies
                    if reply.get('content'):
                        reply_content = reply['content'].strip()
                        if len(reply_content) > 200: reply_content = reply_content[:200] + "..."
                        thanks_info = f"(æ„Ÿè°¢: {reply['thanks_count']})" if reply['thanks_count'] > 0 else ""
                        content_parts.append(f"{j}. {reply['member_username']} {thanks_info}: {reply_content}")
                content_parts.append("")

            content_parts.append("---\n")
        
        full_content = "\n".join(content_parts)
        self.logger.info(f"æ ¼å¼åŒ–åçš„ä¸»é¢˜å†…å®¹æ€»é•¿åº¦: {len(full_content)} å­—ç¬¦")
        return self._truncate_unified_content(full_content) # Still need truncation
    
    def _truncate_unified_content(self, content: str) -> str:
        """æˆªæ–­ç»Ÿä¸€åˆ†æå†…å®¹åˆ°åˆé€‚é•¿åº¦"""
        if len(content) <= self.max_content_length:
            return content
        
        # æ™ºèƒ½æˆªæ–­ï¼šå°è¯•åœ¨ä¸»é¢˜åˆ†éš”ç¬¦å¤„æˆªæ–­
        truncated = content[:self.max_content_length]
        
        # å°è¯•åœ¨ä¸»é¢˜åˆ†éš”ç¬¦"---"å¤„æˆªæ–­
        last_separator = truncated.rfind('---')
        if last_separator > self.max_content_length * 0.7:
            truncated = truncated[:last_separator]
        else:
            # å°è¯•åœ¨æ®µè½åˆ†éš”ç¬¦å¤„æˆªæ–­
            for delimiter in ['\n\n', '\n', 'ã€‚', '.']:
                last_pos = truncated.rfind(delimiter)
                if last_pos > self.max_content_length * 0.8:
                    truncated = truncated[:last_pos + len(delimiter)]
                    break
        
        self.logger.info(f"ç»Ÿä¸€åˆ†æå†…å®¹è¢«æˆªæ–­: {len(content)} -> {len(truncated)} å­—ç¬¦")
        return truncated + "\n\n...[å†…å®¹è¿‡é•¿å·²è¢«æˆªæ–­]"
    
    def generate_node_report(self, node_name: str, hours_back: int = 24,
                           report_type: str = 'hotspot') -> Dict[str, Any]:
        """
        ä¸ºæŒ‡å®šèŠ‚ç‚¹ç”Ÿæˆåˆ†ææŠ¥å‘Š
        """
        try:
            self.logger.info(f"å¼€å§‹ä¸ºèŠ‚ç‚¹ '{node_name}' ç”Ÿæˆ {report_type} æŠ¥å‘Š")

            # æ—¶é—´èŒƒå›´
            end_time = self.get_beijing_time()
            start_time = end_time - timedelta(hours=hours_back)

            # é¦–å…ˆæ£€æŸ¥è¯¥èŠ‚ç‚¹åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ˜¯å¦æœ‰ä»»ä½•ä¸»é¢˜
            cutoff_timestamp = int((datetime.now() - timedelta(hours=hours_back)).timestamp())
            with self.db.get_cursor() as (cursor, connection):
                cursor.execute(
                    "SELECT COUNT(*) as total_count FROM v2ex_topics WHERE node_name = %s AND created_timestamp >= %s",
                    (node_name, cutoff_timestamp)
                )
                total_topics = cursor.fetchone()['total_count']

                # åŒæ—¶æ£€æŸ¥æœ‰å¤šå°‘ä¸»é¢˜æœ‰äº’åŠ¨ï¼ˆå›å¤æˆ–æ„Ÿè°¢ï¼‰
                cursor.execute(
                    "SELECT COUNT(*) as active_count FROM v2ex_topics WHERE node_name = %s AND created_timestamp >= %s AND (replies > 0 OR total_thanks_count > 0)",
                    (node_name, cutoff_timestamp)
                )
                active_topics = cursor.fetchone()['active_count']

                # æ£€æŸ¥çƒ­åº¦åˆ†æ•°å¤§äº0çš„ä¸»é¢˜æ•°é‡
                cursor.execute(
                    "SELECT COUNT(*) as hot_count FROM v2ex_topics WHERE node_name = %s AND created_timestamp >= %s AND hotness_score > 0",
                    (node_name, cutoff_timestamp)
                )
                hot_topics_count = cursor.fetchone()['hot_count']

            self.logger.info(f"èŠ‚ç‚¹ '{node_name}' åœ¨è¿‡å» {hours_back} å°æ—¶å†…ç»Ÿè®¡ï¼šæ€»ä¸»é¢˜æ•°={total_topics}, æœ‰äº’åŠ¨ä¸»é¢˜æ•°={active_topics}, çƒ­é—¨ä¸»é¢˜æ•°={hot_topics_count}")

            # è·å–çƒ­é—¨ä¸»é¢˜ï¼ˆç°åœ¨ä½¿ç”¨æ”¹è¿›çš„å¤šçº§ç­–ç•¥ï¼‰
            hot_topics = self.db.get_hot_topics_by_node(
                node_name=node_name,
                limit=self.top_topics_per_node,
                period_hours=hours_back
            )

            if not hot_topics:
                # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ä¸»é¢˜ï¼Œæ‰©å¤§æ—¶é—´èŒƒå›´å†è¯•ä¸€æ¬¡
                extended_hours = hours_back * 2  # æ‰©å¤§åˆ°48å°æ—¶
                self.logger.warning(f"åœ¨ {hours_back} å°æ—¶å†…æœªæ‰¾åˆ°ä¸»é¢˜ï¼Œå°è¯•æ‰©å¤§åˆ° {extended_hours} å°æ—¶")

                hot_topics = self.db.get_hot_topics_by_node(
                    node_name=node_name,
                    limit=self.top_topics_per_node,
                    period_hours=extended_hours
                )

                if hot_topics:
                    self.logger.info(f"æ‰©å¤§æ—¶é—´èŒƒå›´åæ‰¾åˆ° {len(hot_topics)} ä¸ªä¸»é¢˜")
                    # æ›´æ–°å®é™…ä½¿ç”¨çš„æ—¶é—´èŒƒå›´
                    start_time = end_time - timedelta(hours=extended_hours)
                else:
                    return {
                        'success': False,
                        'error': f"èŠ‚ç‚¹ '{node_name}' åœ¨è¿‡å» {extended_hours} å°æ—¶å†…ä»æ— å¯åˆ†æå†…å®¹",
                        'node_name': node_name,
                        'debug_info': {
                            'total_topics_24h': total_topics,
                            'active_topics_24h': active_topics,
                            'hot_topics_24h': hot_topics_count
                        }
                    }

            # æ‰¹é‡è·å–ä¸»é¢˜è¯¦ç»†ä¿¡æ¯å’Œå›å¤ï¼Œé¿å…N+1æŸ¥è¯¢
            self.logger.info(f"å¼€å§‹æ‰¹é‡è·å– {len(hot_topics)} ä¸ªä¸»é¢˜çš„è¯¦æƒ…...")
            import time
            start_time_db = time.time()
            topic_ids = [topic['id'] for topic in hot_topics]
            hot_topics_data = self.db.get_topics_with_replies_batch(
                topic_ids,
                reply_limit=self.top_replies_per_topic
            )
            db_duration = time.time() - start_time_db
            self.logger.info(f"æ‰¹é‡è·å–ä¸»é¢˜è¯¦æƒ…å®Œæˆï¼Œè€—æ—¶ {db_duration:.2f} ç§’")

            if not hot_topics_data:
                return {
                    'success': False,
                    'error': f"æ— æ³•è·å–èŠ‚ç‚¹ '{node_name}' çš„ä¸»é¢˜è¯¦æƒ…",
                    'node_name': node_name,
                    'debug_info': {
                        'topics_found': len(hot_topics),
                        'topic_ids': topic_ids[:5]  # åªæ˜¾ç¤ºå‰5ä¸ªIDç”¨äºè°ƒè¯•
                    }
                }

            # ç›´æ¥è°ƒç”¨ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆæ–¹æ³•
            return self._generate_unified_report(
                node_name=node_name,
                hot_topics_data=hot_topics_data,
                start_time=start_time,
                end_time=end_time,
                report_type=report_type
            )

        except Exception as e:
            error_msg = f"ç”ŸæˆèŠ‚ç‚¹ '{node_name}' æŠ¥å‘Šå¤±è´¥: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            return {
                'success': False,
                'error': error_msg,
                'node_name': node_name
            }
    
    def generate_global_report(self, hours_back: int = 48, 
                             report_type: str = 'hotspot') -> Dict[str, Any]:
        """
        ç”Ÿæˆå…¨ç«™çƒ­ç‚¹æŠ¥å‘Š
        
        Args:
            hours_back: å›æº¯æ—¶é—´ï¼ˆå°æ—¶ï¼‰
            report_type: æŠ¥å‘Šç±»å‹
            
        Returns:
            æŠ¥å‘Šç”Ÿæˆç»“æœ
        """
        try:
            self.logger.info(f"å¼€å§‹ç”Ÿæˆå…¨ç«™ {report_type} æŠ¥å‘Š")
            
            # æ—¶é—´èŒƒå›´
            end_time = self.get_beijing_time()
            start_time = end_time - timedelta(hours=hours_back)
            
            # è·å–å…¨ç«™çƒ­é—¨ä¸»é¢˜
            hot_topics = self.db.get_hot_topics_by_node(
                node_name=None,  # Noneè¡¨ç¤ºå…¨ç«™
                limit=self.top_topics_per_node,
                period_hours=hours_back
            )
            
            if not hot_topics:
                return {
                    'success': False,
                    'error': f"å…¨ç«™åœ¨è¿‡å» {hours_back} å°æ—¶å†…æ— çƒ­é—¨ä¸»é¢˜"
                }
            
            # æ‰¹é‡è·å–ä¸»é¢˜è¯¦ç»†ä¿¡æ¯
            self.logger.info("å¼€å§‹æ‰¹é‡è·å–ä¸»é¢˜è¯¦æƒ…...")
            import time
            start_time_db = time.time()
            topic_ids = [topic['id'] for topic in hot_topics]
            hot_topics_data = self.db.get_topics_with_replies_batch(
                topic_ids,
                reply_limit=self.top_replies_per_topic
            )
            db_duration = time.time() - start_time_db
            self.logger.info(f"æ‰¹é‡è·å–ä¸»é¢˜è¯¦æƒ…å®Œæˆï¼Œè€—æ—¶ {db_duration:.2f} ç§’")
            
            # ä½¿ç”¨ä¸èŠ‚ç‚¹æŠ¥å‘Šç›¸åŒçš„é€»è¾‘
            return self._generate_unified_report(
                node_name="å…¨ç«™",
                hot_topics_data=hot_topics_data,
                start_time=start_time,
                end_time=end_time,
                report_type=report_type
            )
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆå…¨ç«™æŠ¥å‘Šå¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return {
                'success': False,
                'error': error_msg
            }
    
    def _generate_unified_report(self, node_name: str, hot_topics_data: List[Dict[str, Any]],
                               start_time: datetime, end_time: datetime, 
                               report_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿä¸€æŠ¥å‘Šçš„å†…éƒ¨æ–¹æ³•ï¼ˆå·²å‡çº§ï¼‰"""
        
        # ä½¿ç”¨æ–°çš„æ–¹æ³•æ ¼å¼åŒ–æ‰€æœ‰ä¸»é¢˜å†…å®¹
        unified_content = self._format_topics_for_analysis(hot_topics_data)

        # LLMåˆ†æ
        if not self.llm:
            return {'success': False, 'error': 'LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'}

        # è·å–æŠ¥å‘Šç±»å‹çš„å¯¹åº”prompt
        if report_type == 'hotspot':
            prompt_template = self._get_hotspot_prompt_template()
        else:
            # ä¸ºå…¶ä»–æŠ¥å‘Šç±»å‹å¯ä»¥å®šä¹‰ä¸åŒçš„promptï¼Œæ­¤å¤„ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é»˜è®¤å€¼
            self.logger.warning(f"æŠ¥å‘Šç±»å‹ '{report_type}' æ²¡æœ‰ä¸“é—¨çš„Promptæ¨¡æ¿ï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†æã€‚")
            prompt_template = "è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„ä¸»è¦çœ‹ç‚¹ã€äº‰è®®å’Œç»“è®ºï¼š\n\n{content}"

        llm_result = self.llm.analyze_content(unified_content, prompt_template)
        
        if not llm_result.get('success'):
            return {
                'success': False,
                'error': f"LLMåˆ†æå¤±è´¥: {llm_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            }
        
        # ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜
        if node_name == "å…¨ç«™":
            report_title = f"ğŸŒŸ V2EXå…¨ç«™çƒ­ç‚¹æ´å¯ŸæŠ¥å‘Š"
        else:
            report_title = f"ğŸ“ˆ [{node_name}]èŠ‚ç‚¹çƒ­ç‚¹æ´å¯ŸæŠ¥å‘Š"
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_report = self._generate_markdown_report(
            node_name=node_name,
            analysis_result=llm_result,
            hot_topics_data=hot_topics_data,
            start_time=start_time,
            end_time=end_time,
            report_title=report_title,
            report_type=report_type
        )
        
        # ä¿å­˜æŠ¥å‘Š
        report_data = {
            'node_name': node_name,
            'report_type': report_type,
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'topics_analyzed': len(hot_topics_data),
            'report_title': report_title,
            'report_content': markdown_report,
            'generated_at': self.get_beijing_time()
        }
        
        report_id = self.db.insert_report(report_data)

        final_result = {
            'success': True,
            'report_id': report_id,
            'node_name': node_name,
            'report_type': report_type,
            'topics_analyzed': len(hot_topics_data),
            'report_title': report_title,
            'report_content': markdown_report,
            'report_content_preview': self._truncate_content_for_logging(markdown_report, 300),
            'analysis_provider': llm_result.get('provider'),
            'analysis_model': llm_result.get('model'),
            'generated_at': report_data['generated_at']
        }

        # å°è¯•æ¨é€åˆ°Notion
        try:
            from .notion_client import v2ex_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self.get_beijing_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] {node_name}èŠ‚ç‚¹çƒ­ç‚¹æŠ¥å‘Š ({len(hot_topics_data)}ä¸ªä¸»é¢˜)"

            self.logger.info(f"å¼€å§‹æ¨é€æŠ¥å‘Šåˆ°Notion: {notion_title}")

            notion_result = v2ex_notion_client.create_report_page(
                report_title=notion_title,
                report_content=markdown_report,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"æŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion: {notion_result.get('page_url')}")
                final_result['notion_push'] = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                self.logger.warning(f"æ¨é€åˆ°Notionå¤±è´¥: {notion_result.get('error')}")
                final_result['notion_push'] = {
                    'success': False,
                    'error': notion_result.get('error')
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€åˆ°Notionæ—¶å‡ºé”™: {e}")
            final_result['notion_push'] = {
                'success': False,
                'error': str(e)
            }

        if llm_result.get('partial'):
            final_result['success'] = False
            final_result['error'] = "éƒ¨åˆ†ç»“æœï¼šLLMè¿æ¥ä¸­æ–­"

        return final_result
    
    def _generate_markdown_report(self, node_name: str, analysis_result: Dict[str, Any],
                                hot_topics_data: List[Dict[str, Any]], start_time: datetime,
                                end_time: datetime, report_title: str, 
                                report_type: str) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        
        # æ—¶é—´ä¿¡æ¯
        start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
        end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')
        generate_time = self.get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')
        
        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_lines = [
            f"# {report_title}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {generate_time}*  ",
            f"*æ•°æ®èŒƒå›´: {start_str} - {end_str}*",
            "",
            "---",
            "",
            analysis_result.get('analysis', 'åˆ†æå†…å®¹ç”Ÿæˆå¤±è´¥ã€‚'),
            "",
            "---",
            "",
            "## ğŸ“š æ¥æºæ¸…å• (Source List)",
            ""
        ]
        
        # ç”Ÿæˆæ¥æºæ¸…å•
        for i, topic_data in enumerate(hot_topics_data, 1):
            topic_info = topic_data['topic']
            # å°†æ ‡é¢˜ä¸­çš„æ–¹æ‹¬å·æ›¿æ¢ä¸ºä¸­æ–‡æ–¹æ‹¬å·ï¼Œé¿å…å¹²æ‰°Markdowné“¾æ¥è§£æ
            clean_title = topic_info['title'].replace('[', 'ã€').replace(']', 'ã€‘')
            report_lines.append(
                f"- **[T{i}]**: [{clean_title}]({topic_info['url']}) "
                f"({topic_info['node_name']} | {topic_info['replies']}å›å¤ | {topic_info['total_thanks_count']}æ„Ÿè°¢)"
            )
        
        report_lines.extend(["", "---", ""])
        
        # æŠ€æœ¯ä¿¡æ¯
        if analysis_result.get('provider'):
            report_lines.append(
                f"*åˆ†æå¼•æ“: {analysis_result['provider']} ({analysis_result.get('model', 'unknown')})*"
            )
        
        report_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(hot_topics_data)} ä¸ªçƒ­é—¨ä¸»é¢˜",
            ""
        ])

        if analysis_result.get('partial'):
            report_lines.append("")
            report_lines.append("*æ³¨æ„ï¼šç”±äºä¸åˆ†æå¼•æ“çš„è¿æ¥æ„å¤–ä¸­æ–­ï¼Œæ­¤æŠ¥å‘Šå¯èƒ½ä¸å®Œæ•´ã€‚*")

        report_lines.extend([
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        
        return "\n".join(report_lines)


# å…¨å±€æŠ¥å‘Šç”Ÿæˆå™¨å®ä¾‹
report_generator = V2EXReportGenerator()
